{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 21:02:56.680572: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-03 21:02:56.694878: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-03 21:02:56.713102: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-03 21:02:56.718616: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-03 21:02:56.731456: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 02-03 21:03:01 __init__.py:183] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.1.8: Fast Qwen2 patching. Transformers: 4.48.2.\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.568 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395ae4a8d1634d418de3b6c988a24962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_seq_length = 4096  # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/DeepSeek-R1-Distill-Qwen-14B-unsloth-bnb-4bit\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_inspect():\n",
    "    logic = open(\"logic.py\", \"r\").read()\n",
    "    main_prompt = open(\"main_prompt.md\", \"r\").read()\n",
    "    notes = open(\"notes.txt\",\"r\").read()\n",
    "    return logic,main_prompt,notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_evolve(model,tokenizer,prompt,logic,notes):\n",
    "    FastLanguageModel.for_inference(model)\n",
    "    inputs = tokenizer(\n",
    "        prompt.format(\n",
    "            notes,\n",
    "            logic,\n",
    "            \"\",\n",
    "            \"\"\n",
    "        )\n",
    "    , return_tensors = \"pt\").to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(**inputs, max_new_tokens = 10000, use_cache = True)\n",
    "    return tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract(text, start_tag, end_tag, phrase):\n",
    "    match = re.search(rf\"{re.escape(phrase)}\\s*(.*)\", text, re.DOTALL)\n",
    "    if not match:\n",
    "        return None  # Return None if phrase is not found\n",
    "\n",
    "    extracted_text = match.group(1)  # Extract the matched string, NOT the match object\n",
    "\n",
    "    pattern = re.compile(rf\"{re.escape(start_tag)}(.*?){re.escape(end_tag)}\", re.DOTALL)\n",
    "    match = pattern.search(extracted_text)\n",
    "\n",
    "    return match.group(1).strip() if match else None  # Extract and return text within tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic,main_prompt,notes = self_inspect()\n",
    "response = self_evolve(model,tokenizer,main_prompt,logic,notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Initial Setup\n",
      "\n",
      "- Aim: Create a basic framework for the trading pipeline.\n",
      "- Tasks:\n",
      "  1. Set up initial data collection and preprocessing.\n",
      "  2. Implement a simple trading strategy.\n",
      "  3. Create a basic backtesting module.\n",
      "  4. Initialize logging and performance tracking.\n",
      "- Future Improvements:\n",
      "  - Explore advanced strategies and machine learning models.\n",
      "  - Optimize for performance and scalability.\n",
      "  - Integrate real-time data and live trading.\n"
     ]
    }
   ],
   "source": [
    "print(extract(response[0],\"**NOTESSTART**\",\"**NOTESEND**\",\"(DO NOT REMOVE THIS SENTENCE):\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "# Import necessary libraries\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from datetime import datetime\n",
      "\n",
      "# Data Collection and Preprocessing\n",
      "def fetch_data(ticker, start_date, end_date):\n",
      "    data = pd.DataFrame()  # Placeholder for actual data fetching logic\n",
      "    return data\n",
      "\n",
      "def preprocess_data(data):\n",
      "    # Basic preprocessing: fill NaN values, calculate moving averages, etc.\n",
      "    data.fillna(method='ffill', inplace=True)\n",
      "    data['SMA_20'] = data['Close'].rolling(20).mean()\n",
      "    data['SMA_50'] = data['Close'].rolling(50).mean()\n",
      "    return data\n",
      "\n",
      "# Trading Strategy\n",
      "def simple_strategy(data):\n",
      "    # Simple moving average crossover strategy\n",
      "    signals = pd.DataFrame(index=data.index)\n",
      "    signals['Signal'] = 0\n",
      "    for i in range(len(data)):\n",
      "        if i >= len(data['SMA_20']) and i >= len(data['SMA_50']):\n",
      "            if data['SMA_20'].iloc[i] > data['SMA_50'].iloc[i]:\n",
      "                signals.iloc[i] = 1\n",
      "            elif data['SMA_20'].iloc[i] < data['SMA_50'].iloc[i]:\n",
      "                signals.iloc[i] = -1\n",
      "    return signals\n",
      "\n",
      "# Backtesting Module\n",
      "def backtest(signals, data):\n",
      "    # Calculate returns\n",
      "    returns = pd.Series([0.0]*len(signals))\n",
      "    positions = 0\n",
      "    for i in range(len(signals)):\n",
      "        if signals.iloc[i] == 1:\n",
      "            positions = 1\n",
      "            returns.iloc[i] = data['Close'].iloc[i] - data['Close'].iloc[i-1]\n",
      "        elif signals.iloc[i] == -1:\n",
      "            positions = -1\n",
      "            returns.iloc[i] = data['Close'].iloc[i] - data['Close'].iloc[i-1]\n",
      "        else:\n",
      "            returns.iloc[i] = 0\n",
      "    # Calculate performance metrics\n",
      "    total_return = (1 + returns).cumprod() - 1\n",
      "    return total_return\n",
      "\n",
      "# Main Execution\n",
      "if __name__ == '__main__':\n",
      "    # Fetch data\n",
      "    start_date = '2020-01-01'\n",
      "    end_date = '2023-12-31'\n",
      "    data = fetch_data('BTCUSDT', start_date, end_date)\n",
      "    \n",
      "    # Preprocess data\n",
      "    data = preprocess_data(data)\n",
      "    \n",
      "    # Generate signals\n",
      "    signals = simple_strategy(data)\n",
      "    \n",
      "    # Backtest\n",
      "    total_return = backtest(signals, data)\n",
      "    \n",
      "    # Plot results\n",
      "    plt.figure(figsize=(10, 6))\n",
      "    plt.plot(total_return, label='Backtest Results')\n",
      "    plt.xlabel('Date')\n",
      "    plt.ylabel('Cumulative Return')\n",
      "    plt.title('Backtest Results')\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(extract(response[0],\"**LOGICSTART**\",\"**LOGICEND**\",\"(DO NOT REMOVE THIS SENTENCE):\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
